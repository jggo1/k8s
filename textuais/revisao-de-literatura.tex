\chapter{FUNDAMENTAÇÃO TEÓRICA}
\label{chap:fundamentacaoTeorica}

\section{VIRTUALIZAÇÃO}
\label{sec:virtualizacao}

Virtualização, basicamente, é a técnica de separar aplicação e sistema operacional dos componentes físicos. Por exemplo, uma máquina virtual possui aplicação e sistema operacional como um servidor físico, mas estes não estão vinculados ao software e pode ser disponibilizado onde for mais conveniente. Uma aplicação deve ser executada em um sistema operacional em um determinado software. Com virtualização de aplicação ou apresentação, estas aplicações podem rodar em um servidor ou ambiente centralizado e ser deportada para outros sistemas operacionais e hardwares.

\subsection{\textit{HYPERVISOR}}
\label{sec:hypervisor}

O \textit{hypervisor} é um \textit{firmware} ou hardware que cria e roda máquinas virtuais (\textit{VMs}). O computador no qual o \textit{hypervisor} roda uma ou mais VMs é chamado de máquina hospedeira (\textit{host}), e cada \textit{VM} é chamada de máquina convidada (\textit{guest}). O \textit{hypervisor} se apresenta aos sistemas operacionais convidados como uma plataforma de virtualização e gerencia a execução dos sistemas operacionais convidados. 

Existem dois tipos de hypervisor, o primeiro tipo é conhecido como bare matal, onde o próprio sistema operacional que gerencia as VM, podemos citar o VMware: ESX, Xem, CubeOS, Microsoft Hyper-V. O segudo modelo é o hosted onde o hypervisor se encontra encima do sistema operacional, seja Linux, Windowns ou MacOS, podemos citar o virtualbox, VMware: Workstation, QEMU, OVirt.   

\subsection{VIRTUALIZAÇÃO COMPLETA E PARCIAL}
\label{sec:virtualizacao-completa-parcial}

Como o próprio nome sugere, a virtualização completa realiza toda a abstração do sistema físico, com o objetivo de fornecer ao sistema operacional hóspede uma réplica do hardware  virtualizado pelo hospedeiro. Este tipo dispensa a necessidade de modificar o SO convidado, que trabalha desconhecendo que há virtualização.

Com a virtualização total, as instruções não críticas são executadas diretamente no hardware, enquanto as instruções críticas são interceptadas e executadas pela hypervisor. O sistema operacional visitante, no entanto, sequer tem o conhecimento de que está sendo executado sobre o hypervisor.

Já um SO convidado paravirtualizado tem a assistência de um compilador inteligente que atua na substituição de instruções de SO não virtualizáveis por hiperchamadas (hypercalls) quando for executar uma instrução sensível. Tal procedimento poupa o desempenho, quando comparado ao que foi descrito na virtualização total.

Em relação aos dispositivos de E/S, a paravirtualização permite que as máquinas virtuais usem os drivers do dispositivo físico real sob o controle do hipervisor, o que reduz os problemas de compatibilidade.

\section{CONTAINER LINUX}
\label{sec:linux-countainer}

A \citeonline{redhat1}  em seu artigo "O que é um container Linux?" define container Linux como:
\begin{citacao}
	Um container Linux é um conjunto de um ou mais processos organizados isoladamente do sistema. Todos os arquivos necessários à execução de tais processos são fornecidos por uma imagem distinta. Na prática, os containers Linux são portáteis e consistentes durante toda a migração entre os ambientes de desenvolvimento, teste e produção. Essas características os tornam uma opção muito mais rápida do que os pipelines de desenvolvimento, que dependem da replicação dos ambientes de teste tradicionais.
\end{citacao}  

Por meio dessa definição pode-se perceber que os contaiers são bons no desenvolvimento de software, pois os programadores ao criar seus programas em um ambiente isolado e unificado, tanto na parte do desenvolvimento quanto no uso em produção.    

\begin{figure}[!htb]
	\centering
	\caption{Container LXC}
	\includegraphics[width=0.5\textwidth]{figuras/what-is-a-container.png}
	\fonte{\citeonline{redhat1}}
	\label{fig:figura-exemplo1}
\end{figure}

Para rodar uma aplicação ou serviço, os containers Linux possuem as bibliotecas e as dependências dentro dele mesmo, assim possibilitando a migração entre os ambientes como o de desenvolvimento, teste e produção. A imagem mostra a camada de aplicações rodando em cima da camada de aquivos de suportes, que são as dependências e bibliotecas, isso tudo de maneira isolada do sistema operacional.    


\subsection{EVOLUÇÃO DOS CONTAINERS}

Os conteiners não surgiram no Linux, mas surgiu inicialmente no FreeBSD em 2000 como jails, essa tecnologia ê capaz de particionar um sistema FreeBSD em vários subsistemas ou celas (por causa disso o nome "jails" ). Eles foram desenvolvidos para serem ambientes seguros que podiam ser compartilhados entre os membros de equipe ou colegas de trabalho. Os jails tem como propósito, criar processos em um ambiente isolado utilizando o chroot ("Changing root" ou trocando a raiz), que consiste em mentir para os processos, para achar que a raiz ou o começo do sistema de arquivos está em uma determinada pasta, fazendo eles percam o acesso ao sistema de arquivos real. Um sistema operacional inteiro rodado  de maneira isolada a partir de uma pasta.  Contudo a implementação estava incompleta e com o tempo foram descobertos métodos de escapar do ambiente em jail. 

Logo após, foram implementadas no Linux os grupos de controle (cgroups) que limita o uso de recursos por um processo ou grupo de processos. Com a mudança do sistema de inicialização padrão do sysV para systemd, que possui uma melhor integração com o cgroups, possibilitou ter mais controle sobre os processos isolados. Ambas as tecnologias, além de adicionarem um controle geral ao Linux, serviram como estrutura para a separação eficaz de ambientes.

Com os avanços em namespaces de kernel, pode-se virtualizar, desde IDs de processos a nomes de rede. E os namespaces de usuários “permitem realizar mapeamentos de IDs de usuários e grupos por namespace. No que diz respeito a containers, isso faz com que os usuários e grupos podem ter privilégios para executar determinadas operações dentro de um container, sem ter esses mesmos privilégios fora dele. Por conta disso surgiu o projeto Linux Containers (LXC) que melhorou a experiência do usuário na utilização de containers, contribuindo com ferramentas para facilitar a inicialização de containers com uma interface de linha de comando simples.

Porém, mesmo com os avanços do LXC, estava longe de ser amigável com o publico. Com isso surgiu o docker, mudando completamento a forma de criar, gerenciar, compartir, depurar e de iniciar containers. Levando a tecnologia de containers a outro patamar, sendo utilizado pelas maiores impressas no mundo. 

\section{CONTAINER ENGINE}
\label{sec:countainerEngine}

Em 2008, o Docker entrou em cena (por meio do dotCloud) com sua tecnologia de container homônima. A tecnologia Docker adicionou muitos dos novos conceitos e ferramentas: uma interface de linha de comando simples para executar e criar novas imagens em camadas, um daemon de servidor, uma biblioteca de imagens de container pré-criadas e o conceito de servidor de registros. Combinadas, essas tecnologias possibilitaram aos usuários criar novos containers em camadas com rapidez e compartilhá-los facilmente com outras pessoas.

A Red Hat reconheceu o poder da colaboração nesse novo ecossistema e usou a tecnologia subjacente no nosso OpenShift Container Platform. Para afastar o receio de haver um único fornecedor controlando uma tecnologia tão importante, a Docker Inc. contribuiu com muitos dos componentes subjacentes utilizados em projetos open source realizados pela comunidade (o runc faz parte da Open Containers Initiative (OCI) e o containerd foi transferido para o CNCF).

Há três padrões principais que garantem a interoperabilidade das tecnologias de containers: as especificações Image, Distribution e Runtime da OCI. A combinação dessas especificações permite que projetos da comunidade, soluções comerciais e provedores de cloud criem tecnologias de container interoperáveis (por exemplo, pense em uma situação em que você precisa introduzir imagens personalizadas no servidor de registro do provedor de cloud). Atualmente, a Red Hat e a Docker, juntamente com muitas outras organizações, são membros da Open Container Initiative, cujo objetivo é padronizar as tecnologias de containers no setor open source.

\begin{figure}[!htb]
	\centering
	\caption{LXC vs docker}
	\includegraphics[width=0.9\textwidth]{figuras/traditional-linux-containers-vs-docker_0.png}
	\fonte{\citeonline{redhat1}}
	\label{fig:lxc-vs-docker}
\end{figure}

\section{VIRTUALIZAÇÃO VS CONTAINER}
\label{sec:virtualizaçãos-vs-container}

Em bora a virtualização e os containers se pareçam muito, sáo duas tecnologias diferentes, que complementam-se. De acordo com a \citeonline{redhat1}, a virtualização tem o proposito de executar sistemas operacionais simultaneamente em um único sistema de hardware. Já os containers compartilham o mesmo núcleo do sistema operacional e isolam os processos da aplicação do restante do sistema. Os containers Linux são extremamente portáteis, mas
devem ser compatíveis com o sistema operacional subjacente.

A virtualização usa um hipervisor para emular o hardware e essa não é uma solução tão leve quanto o uso de containers. Os containers são executados de maneira nativa no sistema operacional. Em comparação com as máquinas virtuais, executar containers Linux consome menos recursos e facilita o gerenciamento dos processos. Além
disso, é possível orquestrar as aplicações em vários containers em diversas nuvens.

\begin{figure}[!htb] 
	\centering
	\caption{Virtualização vs container}
	\includegraphics[width=0.9\textwidth]{figuras/virtualization-vs-containers.png}
	\fonte{\citeonline{redhat1}}
	\label{fig:virtualization-vs-containers}
\end{figure}

%Os containers Linux são mais um salto evolucionário no desenvolvimento, implantação e gerenciamento de aplicações. Com as imagens de containers Linux, é possível ter portabilidade e controle de versão. Assim, isso ajuda a garantir que os trabalhos contidos no laptop do desenvolvedor sejam executados corretamente no ambiente de produção. Em comparação com as máquinas virtuais, executar containers Linux consome menos recursos, oferece uma interface padrão (início, interrupção, variáveis de ambiente etc.), mantém a aplicação isolada e facilita o gerenciamento dos processos, como parte de uma aplicação maior (vários containers). Além disso, é possível orquestrar as aplicações em vários containers em diversas clouds.



